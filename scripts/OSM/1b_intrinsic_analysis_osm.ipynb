{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "<img src=\"../../images/BikeDNA_logo.svg\" width=\"250\"  alt=\"BikeDNA logo\" style=\"display:block; margin-left: auto; margin-right: auto;\">\n",
    "<a href=\"https://github.com/anerv/BikeDNA\">Github</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b. Intrinsic Analysis of OSM Data\n",
    "This notebook analyzes the quality of OSM bicycle infrastructure data for a given area. The quality assessment is *intrinsic*, i.e. based only on the one input data set without makeing use of external information. For an extrinsic quality assessment that compares the OSM data to a user-provided reference data set, see the notebooks 3a and 3b.\n",
    "\n",
    "The analysis assesses the *fitness for purpose* ([Barron et al., 2014](https://onlinelibrary.wiley.com/doi/10.1111/tgis.12073)) of OSM data for a given area. Outcomes of the analysis can be relevant for bicycle planning and research - especially for projects that include a network analysis of bicycle infrastructure, in which case the topology of the geometries is of particular importance.\n",
    "\n",
    "Since the assessment does not make use of an external reference data set as the ground truth, no universal claims of data quality can be made. The idea is rather to enable those working with OSM-based bicycle networks to assess whether the data are good enough for their particular use case. The analysis assists in finding potential data quality issues but leaves the final interpretation of the results to the user.\n",
    "\n",
    "The notebook makes use of quality metrics from a range of previous projects investigating OSM/VGI data quality, such as [Ferster et al. (2020)](https://www.tandfonline.com/doi/full/10.1080/15568318.2018.1519746), [Hochmair et al. (2015)](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12081), [Barron et al. (2014)](https://onlinelibrary.wiley.com/doi/10.1111/tgis.12073), and [Neis et al. (2012](https://www.mdpi.com/1999-5903/4/1/1))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Prerequisites &amp; Input/Output</b>\n",
    "<p>\n",
    "Run notebook 1a in advance.  \n",
    "    \n",
    "Output files of this notebook (data, maps, plots) are saved to the <span style=\"font-family:courier;\">../results/OSM/[study_area]/</span> subfolders.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Familiarity required</b>\n",
    "<p>\n",
    "For a correct interpretation of some of the metrics for spatial data quality, some familiarity with the area is necessary.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "**Sections**\n",
    "* [Data completeness](#Data-completeness)\n",
    "    * [Network density](#Network-density)\n",
    "* [OSM tag analysis](#OSM-tag-analysis)\n",
    "    * [Missing tags](#Missing-tags)\n",
    "    * [Incompatible tags](#Incompatible-tags)\n",
    "    * [Tagging patterns](#Tagging-patterns)\n",
    "* [Network topology](#Network-topology)\n",
    "    * [Simplification outcome](#Simplification-outcome)\n",
    "    * [Dangling nodes](#Dangling-nodes)\n",
    "    * [Under/overshoots](#Under/overshoots)\n",
    "    * [Missing intersection nodes](#Missing-intersection-nodes)\n",
    "* [Network components](#Network-components)\n",
    "    * [Disconnected components](#Disconnected-components)\n",
    "    * [Components per grid cell](#Components-per-grid-cell)\n",
    "    * [Component length distribution](#Component-length-distribution)\n",
    "    * [Largest connected component](#Largest-connected-component)\n",
    "    * [Missing links](#Missing-links)\n",
    "    * [Component connectivity](#Component-connectivity)\n",
    "* [Summary](#Summary)\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "outputs": [],
   "source": [
    "# Load libraries, settings and data\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "import contextily as cx\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from matplotlib import cm, colors\n",
    "\n",
    "from src import evaluation_functions as eval_func\n",
    "from src import plotting_functions as plot_func\n",
    "\n",
    "%run ../settings/yaml_variables.py\n",
    "%run ../settings/plotting.py\n",
    "%run ../settings/tiledict.py\n",
    "%run ../settings/load_osmdata.py\n",
    "%run ../settings/df_styler.py\n",
    "%run ../settings/paths.py\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "grid = osm_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data completeness\n",
    "\n",
    "### Network density\n",
    "\n",
    "In this setting, network density refers to the length of edges or number of nodes per km2. This is the usual definition of network density in spatial (road) networks, which is distinct from the *structural* network density known more generally in network science. Without comparing to a reference data set, network density does not in itself indicate spatial data quality. For anyone familiar with the study area, network density can however indicate whether parts of the area appear to be under- or over-mapped.\n",
    "\n",
    "**Method**\n",
    "\n",
    "The density here is not based on the geometric length of edges, but instead on the computed length of the infrastructure. For example, a 100-meter-long bidirectional path contributes with 200 meters of bicycle infrastructure. This method is used to take into account different ways of mapping bicycle infrastructure, which otherwise can introduce large deviations in network density. With `compute_network_density`, the number of elements (nodes, dangling nodes, and total infrastructure length) per unit area is calculated. The density is computed twice: first for the study area for both the entire network ('global density'), then for each of the grid cells ('local density'). Both global and local densities are computed for the entire network and for protected and unprotected infrastructure.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Since the analysis conducted here is intrinsic, i.e. it makes no use of external information, it cannot be known whether a low-density value is due to incomplete mapping, or due to actual lack of infrastructure in the area. However, a comparison of the grid cell density values can provide some insights, for example:\n",
    "* lower-than-average infrastructure density indicates a locally sparser network\n",
    "* higher-than-average node density indicates that there are relatively many intersections in a grid cell\n",
    "* higher-than-average dangling node density indicates that there are relatively many dead ends in a grid cell\n",
    "\n",
    "#### Global network density\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire study area\n",
    "edge_density, node_density, dangling_node_density = eval_func.compute_network_density(\n",
    "    (osm_edges_simplified, osm_nodes_simplified),\n",
    "    grid.unary_union.area,\n",
    "    return_dangling_nodes=True,\n",
    ")\n",
    "\n",
    "density_results = {}\n",
    "density_results[\"edge_density_m_sqkm\"] = edge_density\n",
    "density_results[\"node_density_count_sqkm\"] = node_density\n",
    "density_results[\"dangling_node_density_count_sqkm\"] = dangling_node_density\n",
    "\n",
    "osm_protected = osm_edges_simplified.loc[osm_edges_simplified.protected == \"protected\"]\n",
    "osm_unprotected = osm_edges_simplified.loc[\n",
    "    osm_edges_simplified.protected == \"unprotected\"\n",
    "]\n",
    "osm_mixed = osm_edges_simplified.loc[osm_edges_simplified.protected == \"mixed\"]\n",
    "\n",
    "osm_data = [osm_protected, osm_unprotected, osm_mixed]\n",
    "labels = [\"protected_density\", \"unprotected_density\", \"mixed_density\"]\n",
    "\n",
    "for data, label in zip(osm_data, labels):\n",
    "    if len(data) > 0:\n",
    "        osm_edge_density_type, _ = eval_func.compute_network_density(\n",
    "            (data, osm_nodes_simplified),\n",
    "            grid.unary_union.area,\n",
    "            return_dangling_nodes=False,\n",
    "        )\n",
    "        density_results[label + \"_m_sqkm\"] = osm_edge_density_type\n",
    "    else:\n",
    "        density_results[label + \"_m_sqkm\"] = 0\n",
    "\n",
    "protected_edge_density = density_results[\"protected_density_m_sqkm\"]\n",
    "unprotected_edge_density = density_results[\"unprotected_density_m_sqkm\"]\n",
    "mixed_protection_edge_density = density_results[\"mixed_density_m_sqkm\"]\n",
    "\n",
    "print(f\"For the entire study area, there are:\")\n",
    "print(f\"- {edge_density:.2f} meters of bicycle infrastructure per km2.\")\n",
    "print(f\"- {node_density:.2f} nodes in the bicycle network per km2.\")\n",
    "print(\n",
    "    f\"- {dangling_node_density:.2f} dangling nodes in the bicycle network per km2.\"\n",
    ")\n",
    "print(\n",
    "    f\"- {protected_edge_density:.2f} meters of protected bicycle infrastructure per km2.\"\n",
    ")\n",
    "print(\n",
    "    f\"- {unprotected_edge_density:.2f} meters of unprotected bicycle infrastructure per km2.\"\n",
    ")\n",
    "print(\n",
    "    f\"- {mixed_protection_edge_density:.2f} meters of mixed protection bicycle infrastructure per km2.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stats to csv\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"metric\": [\n",
    "            \"meters of bicycle infrastructure per square km\",\n",
    "            \"nodes in the bicycle network per square km\",\n",
    "            \"dangling nodes in the bicycle network per square km\",\n",
    "            \"meters of protected bicycle infrastructure per square km\",\n",
    "            \"meters of unprotected bicycle infrastructure per square km\",\n",
    "            \"meters of mixed protection bicycle infrastructure per square km\",\n",
    "        ],\n",
    "        \"value\": [\n",
    "            np.round(edge_density, 2),\n",
    "            np.round(node_density, 2),\n",
    "            np.round(dangling_node_density, 2),\n",
    "            np.round(protected_edge_density, 2),\n",
    "            np.round(unprotected_edge_density, 2),\n",
    "            np.round(mixed_protection_edge_density, 2),\n",
    "        ],\n",
    "    }\n",
    ").to_csv(osm_results_data_fp + \"stats_area.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local network density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per grid cell\n",
    "results_dict = {}\n",
    "data = (osm_edges_simp_joined, osm_nodes_simp_joined.set_index(\"osmid\"))\n",
    "\n",
    "[\n",
    "    eval_func.run_grid_analysis(\n",
    "        grid_id,\n",
    "        data,\n",
    "        results_dict,\n",
    "        eval_func.compute_network_density,\n",
    "        grid[\"geometry\"].loc[grid.grid_id == grid_id].area.values[0],\n",
    "        return_dangling_nodes=True,\n",
    "    )\n",
    "    for grid_id in grid_ids\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\")\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df.rename(\n",
    "    columns={\n",
    "        \"index\": \"grid_id\",\n",
    "        0: \"osm_edge_density\",\n",
    "        1: \"osm_node_density\",\n",
    "        2: \"osm_dangling_node_density\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "grid = eval_func.merge_results(grid, results_df, \"left\")\n",
    "\n",
    "osm_protected = osm_edges_simp_joined.loc[\n",
    "    osm_edges_simp_joined.protected == \"protected\"\n",
    "]\n",
    "osm_unprotected = osm_edges_simp_joined.loc[\n",
    "    osm_edges_simp_joined.protected == \"unprotected\"\n",
    "]\n",
    "osm_mixed = osm_edges_simp_joined.loc[osm_edges_simp_joined.protected == \"mixed\"]\n",
    "\n",
    "osm_data = [osm_protected, osm_unprotected, osm_mixed]\n",
    "\n",
    "osm_labels = [\"osm_protected_density\", \"osm_unprotected_density\", \"osm_mixed_density\"]\n",
    "\n",
    "for data, label in zip(osm_data, osm_labels):\n",
    "    if len(data) > 0:\n",
    "        results_dict = {}\n",
    "        data = (osm_edges_simp_joined.loc[data.index], osm_nodes_simp_joined)\n",
    "        [\n",
    "            eval_func.run_grid_analysis(\n",
    "                grid_id,\n",
    "                data,\n",
    "                results_dict,\n",
    "                eval_func.compute_network_density,\n",
    "                grid[\"geometry\"].loc[grid.grid_id == grid_id].area.values[0],\n",
    "            )\n",
    "            for grid_id in grid_ids\n",
    "        ]\n",
    "\n",
    "        results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\")\n",
    "        results_df.reset_index(inplace=True)\n",
    "        results_df.rename(columns={\"index\": \"grid_id\", 0: label}, inplace=True)\n",
    "        results_df.drop(1, axis=1, inplace=True)\n",
    "\n",
    "        grid = eval_func.merge_results(grid, results_df, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Network density grid plots\n",
    "         \n",
    "set_renderer(renderer_map)\n",
    "plot_cols = [\"osm_edge_density\", \"osm_node_density\", \"osm_dangling_node_density\"]\n",
    "plot_titles = [\n",
    "    area_name+\": OSM edge density\",\n",
    "    area_name+\": OSM node density\",\n",
    "    area_name+\": OSM dangling node density\",\n",
    "]\n",
    "filepaths = [\n",
    "    osm_results_static_maps_fp + \"density_edge_osm\",\n",
    "    osm_results_static_maps_fp + \"density_node_osm\",\n",
    "    osm_results_static_maps_fp + \"density_danglingnode_osm\",\n",
    "]\n",
    "cmaps = [pdict[\"pos\"], pdict[\"pos\"], pdict[\"pos\"]]\n",
    "no_data_cols = [\"count_osm_edges\", \"count_osm_nodes\", \"count_osm_nodes\"]\n",
    "\n",
    "plot_func.plot_grid_results(\n",
    "    grid=grid,\n",
    "    plot_cols=plot_cols,\n",
    "    plot_titles=plot_titles,\n",
    "    filepaths=filepaths,\n",
    "    cmaps=cmaps,\n",
    "    alpha=pdict[\"alpha_grid\"],\n",
    "    cx_tile=cx_tile_2,\n",
    "    no_data_cols=no_data_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Densities of protected and unprotected infrastructure\n",
    "\n",
    "In BikeDNA, *protected infrastructure* refers to all bicycle infrastructure which is either separated from car traffic by for example an elevated curb, bollards, or other physical barriers, or for cycle tracks that are not adjacent to a street.\n",
    "\n",
    "*Unprotected infrastructure* are all other types of lanes that are dedicated for bicyclists, but which only are separated by car traffic by e.g., a painted line on the street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Network density grid plots\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "plot_cols = [\"osm_protected_density\", \"osm_unprotected_density\", \"osm_mixed_density\"]\n",
    "plot_titles = [\n",
    "    area_name+\": OSM protected infrastructure density (m/km2)\",\n",
    "    area_name+\": OSM unprotected infrastructure density for (m/km2)\",\n",
    "    area_name+\": OSM mixed protection infrastructure density (m/km2)\",\n",
    "]\n",
    "filepaths = [\n",
    "    osm_results_static_maps_fp + \"density_protected_osm\",\n",
    "    osm_results_static_maps_fp + \"density_unprotected_osm\",\n",
    "    osm_results_static_maps_fp + \"density_mixed_osm\",\n",
    "]\n",
    "\n",
    "cmaps = [pdict[\"pos\"]] * len(plot_cols)\n",
    "no_data_cols = [\"osm_protected_density\", \"osm_unprotected_density\", \"osm_mixed_density\"]\n",
    "norm_min = [0] * len(plot_cols)\n",
    "norm_max = [max(grid[plot_cols].fillna(value=0).max())] * len(plot_cols)\n",
    "\n",
    "plot_func.plot_grid_results(\n",
    "    grid=grid,\n",
    "    plot_cols=plot_cols,\n",
    "    plot_titles=plot_titles,\n",
    "    filepaths=filepaths,\n",
    "    cmaps=cmaps,\n",
    "    alpha=pdict[\"alpha_grid\"],\n",
    "    cx_tile=cx_tile_2,\n",
    "    no_data_cols=no_data_cols,\n",
    "    use_norm=True,\n",
    "    norm_min=norm_min,\n",
    "    norm_max=norm_max,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSM tag analysis\n",
    "\n",
    "For many practical and research purposes, more information than just the presence/absence of bicycle infrastructure is of interest. Information about e.g. the width of the infrastructure, speed limits, streetlights, etc. can be of high relevance, for example when evaluating the bike friendliness of an area or an individual network segment. The presence of these tags describing attributes of the bicycle infrastructure is however highly unevenly distributed in OSM, which poses a barrier to evaluations of bikeability and traffic stress. Likewise, the lack of restrictions on how OSM features can be tagged sometimes result in conflicting tags which can undermine the evaluation of cycling conditions.\n",
    "\n",
    "This section includes analyzes of missing tags (edges with tags that lack information), incompatible tags (edges with tags labelled with two or more contradictory tags), and tagging patterns (the spatial variation of which tags are being used to describe bicycle infrastructure).\n",
    "\n",
    "For the evaluation of tags, the non-simplified edges should be used to avoid issues with tags that have been aggregated in the simplification process.\n",
    "\n",
    "### Missing tags\n",
    "\n",
    "The information that is required or desirable to obtain from the OSM tags depends on the use case - for example, the tag `lit` for a project that studies light conditions on cycle paths. The workflow below allows to quickly analyze the percentage of network edges that have a value available for the tag of interest. \n",
    "\n",
    "**Method**\n",
    "\n",
    "We analyze all tags of interest as defined in the `existing_tag_analysis` section of `config.yml`. For each of these tags, `analyze_existing_tags` is used to compute the total number and the percentage of edges that have a corresponding tag value.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "On the study area level, a higher percentage of existing tag values indicates in principle a higher quality of the data set. However, this is different from an estimation of whether the existing tag values are truthful. On the grid cell level, lower-than-average percentages for existing tag values can indicate a more poorly mapped area. However, the percentages are less informative for grid cells with a low number of edges: for example, if a cell contains one single edge that has a tag value for `lit`, the percentage of existing tag values is 100% - but given that there is only 1 data point, this is less informative than, say, a value of 80% for a cell that contains 200 edges.\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>User configurations</b>\n",
    "<br>\n",
    "<br>\n",
    "In the analysis of OSM tags, user settings are used for:\n",
    "<br>\n",
    "<ul>\n",
    "  <li>defining the tags to analyze for missing tags (<span style=\"font-family: monospace\">missing_tag_analysis</span>) </li>\n",
    "  <li>defining incompatible tag value combinations (<span style=\"font-family: monospace\">incompatible_tags_analysis</span>) </li>\n",
    "  <li>the visualization of tagging of bicycle infrastructure (<span style=\"font-family: monospace\">bicycle_infrastructure_queries</span>) </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global missing tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Analysing tags describing:\")\n",
    "for k in existing_tag_dict.keys():\n",
    "    print(k, \"-\", end=\" \")\n",
    "print(\"\\n\")\n",
    "\n",
    "existing_tags_results = eval_func.analyze_existing_tags(osm_edges, existing_tag_dict)\n",
    "\n",
    "for key, value in existing_tags_results.items():\n",
    "    print(\n",
    "        f\"{key}: {value['count']} out of {len(osm_edges)} edges ({value['count']/len(osm_edges)*100:.2f}%) have information.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{key}: {round(value['length']/1000)} out of {round(osm_edges.geometry.length.sum()/1000)} km ({100*value['length']/osm_edges.geometry.length.sum():.2f}%) have information.\"\n",
    "    )\n",
    "    print(\"\\n\")\n",
    "\n",
    "results_dict = {}\n",
    "[\n",
    "    eval_func.run_grid_analysis(\n",
    "        grid_id,\n",
    "        osm_edges_joined,\n",
    "        results_dict,\n",
    "        eval_func.analyze_existing_tags,\n",
    "        existing_tag_dict,\n",
    "    )\n",
    "    for grid_id in grid_ids\n",
    "]\n",
    "\n",
    "# compute the length of osm edges in each grid cell to use for pct missing tags based on length\n",
    "grid_feature_len = eval_func.length_features_in_grid(osm_edges_joined, \"osm_edges\")\n",
    "grid = eval_func.merge_results(grid, grid_feature_len, \"left\")\n",
    "\n",
    "\n",
    "restructured_results = {}\n",
    "\n",
    "for key, value in results_dict.items():\n",
    "\n",
    "    unpacked_results = {}\n",
    "\n",
    "    for tag, _ in existing_tag_dict.items():\n",
    "\n",
    "        unpacked_results[tag + \"_count\"] = value[tag][\"count\"]\n",
    "        unpacked_results[tag + \"_length\"] = value[tag][\"length\"]\n",
    "\n",
    "    restructured_results[key] = unpacked_results\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(restructured_results, orient=\"index\")\n",
    "cols = results_df.columns\n",
    "new_cols = [\"existing_tags_\" + c for c in cols]\n",
    "results_df.columns = new_cols\n",
    "results_df[\"existing_tags_sum\"] = results_df[new_cols].sum(axis=1)\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df.rename(columns={\"index\": \"grid_id\"}, inplace=True)\n",
    "\n",
    "grid = eval_func.merge_results(grid, results_df, \"left\")\n",
    "\n",
    "for c in new_cols:\n",
    "    if \"count\" in c:\n",
    "        grid[c + \"_pct\"] = round(grid[c] / grid.count_osm_edges * 100, 2)\n",
    "        grid[c + \"_pct_missing\"] = 100 - grid[c + \"_pct\"]\n",
    "\n",
    "    elif \"length\" in c:\n",
    "        grid[c + \"_pct\"] = round(grid[c] / grid.length_osm_edges * 100, 2)\n",
    "        grid[c + \"_pct_missing\"] = 100 - grid[c + \"_pct\"]\n",
    "\n",
    "existing_tags_pct = {}\n",
    "\n",
    "existing_tags_pct = {}\n",
    "\n",
    "for k, v in existing_tags_results.items():\n",
    "\n",
    "    pct_dict = {}\n",
    "\n",
    "    pct_dict[\"count_pct\"] = (v[\"count\"] / len(osm_edges)) * 100\n",
    "    pct_dict[\"length_pct\"] = (v[\"length\"] / osm_edges.geometry.length.sum()) * 100\n",
    "\n",
    "    existing_tags_pct[k] = pct_dict\n",
    "\n",
    "for k, v in existing_tags_results.items():\n",
    "    merged_results = v | existing_tags_pct[k]\n",
    "\n",
    "    existing_tags_results[k] = merged_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "\n",
    "# Initialize lists with values for entire data set\n",
    "edgecount_list = [len(osm_edges)]\n",
    "kmcount_list = [round(osm_edges.geometry.length.sum() / 1000)]\n",
    "keys_list = [\"TOTAL\"]\n",
    "\n",
    "for key, value in existing_tags_results.items():\n",
    "    keys_list.append(key)\n",
    "    edgecount_list.append(value[\"count\"])\n",
    "    kmcount_list.append(round(value[\"length\"] / 1000))\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"tag\": keys_list, \"edge count\": edgecount_list, \"km (rounded)\": kmcount_list}\n",
    ").to_csv(osm_results_data_fp + \"stats_tags.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local missing tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Plot pct missing for count\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "count_cols = [c for c in cols if 'count' in c]\n",
    "filepaths = [osm_results_static_maps_fp + \"tagsmissing_\" + c + '_osm' for c in count_cols]\n",
    "plot_cols = [\"existing_tags_\" + c + \"_pct_missing\" for c in count_cols]\n",
    "count_cols = [c.removesuffix('_count') for c in count_cols]\n",
    "plot_titles = [area_name+\": percent of missing OSM tags for: \" + c for c in count_cols]\n",
    "\n",
    "cmaps = [pdict[\"neg\"]] * len(plot_cols)\n",
    "no_data_cols = [\"count_osm_edges\"] * len(plot_cols)\n",
    "\n",
    "plot_func.plot_grid_results(\n",
    "    grid=grid,\n",
    "    plot_cols=plot_cols,\n",
    "    plot_titles=plot_titles,\n",
    "    filepaths=filepaths,\n",
    "    cmaps=cmaps,\n",
    "    alpha=pdict[\"alpha_grid\"],\n",
    "    cx_tile=cx_tile_2,\n",
    "    no_data_cols=no_data_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "noex"
    ]
   },
   "outputs": [],
   "source": [
    "#  Plot pct missing based on the length of the edges with missing tags\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "length_cols = [c for c in cols if 'length' in c]\n",
    "plot_titles = [area_name+\": percent of missing OSM tags for: \" + c for c in length_cols]\n",
    "filepaths = [osm_results_static_maps_fp + \"tagsmissing_\" + c + '_osm' for c in length_cols]\n",
    "plot_cols = [\"existing_tags_\" + c + \"_pct_missing\" for c in length_cols]\n",
    "plot_titles = [c.replace(\"_\", \" (\") for c in plot_titles]\n",
    "plot_titles = [c + \")\" for c in plot_titles]\n",
    "\n",
    "cmaps = [pdict[\"neg\"]] * len(plot_cols)\n",
    "no_data_cols = [\"count_osm_edges\"] * len(plot_cols)\n",
    "\n",
    "plot_func.plot_grid_results(\n",
    "    grid=grid,\n",
    "    plot_cols=plot_cols,\n",
    "    plot_titles=plot_titles,\n",
    "    filepaths=filepaths,\n",
    "    cmaps=cmaps,\n",
    "    alpha=pdict[\"alpha_grid\"],\n",
    "    cx_tile=cx_tile_2,\n",
    "    no_data_cols=no_data_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incompatible tags\n",
    "\n",
    "Given that the tags in OSM data lack coherency at times and there are no restrictions in the tagging process (cf. [Barron et al., 2014](https://onlinelibrary.wiley.com/doi/10.1111/tgis.12073)), incompatible tags might be present in the data set. For example, an edge might be tagged with the following two contradicting key-value pairs: `bicycle_infrastructure = yes` and `bicycle = no`. \n",
    "\n",
    "**Method**\n",
    "\n",
    "In the `config.yml` file, a list of incompatible key-value pairs for tags in the `incompatible_tags_analysis` is defined. Since there is no limitation to which tags a data set could potentially contain, the list is, by definition, non-exhaustive, and can be adjusted by the user. In the section below, `check_incompatible_tags` is run, which identifies all incompatibility instances for a given area, first on the study area level and then on the grid cell level.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Incompatible tags are an undesired feature of the data set and render the corresponding data points invalid; there is no straightforward way to resolve the arising issues automatically, making it necessary to either correct the tag manually or to exclude the data point from the data set. A higher-than-average number of incompatible tags in a grid cell suggests local mapping issues.\n",
    "\n",
    "#### Global incompatible tags (total number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incompatible_tags_results = eval_func.check_incompatible_tags(\n",
    "    osm_edges, incompatible_tags_dict, store_edge_ids=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"In the entire data set, there are {sum(len(lst) for lst in incompatible_tags_results.values())} incompatible tag combinations (of those defined in the configuration file).\"\n",
    ")\n",
    "\n",
    "results_dict = {}\n",
    "[\n",
    "    eval_func.run_grid_analysis(\n",
    "        grid_id,\n",
    "        osm_edges_joined,\n",
    "        results_dict,\n",
    "        eval_func.check_incompatible_tags,\n",
    "        incompatible_tags_dict,\n",
    "    )\n",
    "    for grid_id in grid_ids\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    index=results_dict.keys(), columns=results_dict[list(results_dict.keys())[0]].keys()\n",
    ")\n",
    "\n",
    "for i in results_df.index:\n",
    "    for j in results_df.columns:\n",
    "        results_df.at[i, j] = results_dict[i][j]\n",
    "\n",
    "cols = results_df.columns\n",
    "new_cols = [\"incompatible_tags_\" + c for c in cols]\n",
    "results_df.columns = new_cols\n",
    "results_df[\"incompatible_tags_sum\"] = results_df[new_cols].sum(axis=1)\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df.rename(columns={\"index\": \"grid_id\"}, inplace=True)\n",
    "grid = eval_func.merge_results(grid, results_df, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df = pd.DataFrame(\n",
    "    index=incompatible_tags_results.keys(), data=incompatible_tags_results.values()\n",
    ")\n",
    "edge_ids = []\n",
    "for index, row in df.iterrows():\n",
    "    edge_ids.append(row.to_list())\n",
    "\n",
    "df[\"edge_id\"] = edge_ids\n",
    "incomp_df = df[[\"edge_id\"]]\n",
    "\n",
    "incomp_df.to_csv(osm_results_data_fp + \"incompatible_tags.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local incompatible tags (per grid cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview plots (grid)\n",
    "\n",
    "if len(new_cols) > 0:\n",
    "\n",
    "    set_renderer(renderer_map)\n",
    "    fig, ax = plt.subplots(1, figsize=pdict[\"fsmap\"])\n",
    "\n",
    "    grid.loc[grid.incompatible_tags_sum == 0].plot(\n",
    "        ax=ax, alpha=pdict[\"alpha_grid\"], color=mpl.colors.rgb2hex(incompatible_false_patch.get_facecolor())\n",
    "    )\n",
    "    grid.loc[grid.incompatible_tags_sum > 0].plot(\n",
    "        ax=ax, alpha=pdict[\"alpha_grid\"], color=mpl.colors.rgb2hex(incompatible_true_patch.get_facecolor())\n",
    "    )\n",
    "\n",
    "    # add no data patches\n",
    "    grid[grid[\"count_osm_edges\"].isnull()].plot(\n",
    "        ax=ax,\n",
    "        facecolor=pdict[\"nodata_face\"],\n",
    "        edgecolor=pdict[\"nodata_edge\"],\n",
    "        linewidth= pdict[\"line_nodata\"],\n",
    "        hatch=pdict[\"nodata_hatch\"],\n",
    "        alpha=pdict[\"alpha_nodata\"],\n",
    "    )\n",
    "\n",
    "    ax.legend(\n",
    "        handles=[incompatible_true_patch, incompatible_false_patch, nodata_patch],\n",
    "        loc=\"upper right\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(area_name+\": OSM incompatible tag combinations\")\n",
    "    ax.set_axis_off()\n",
    "    cx.add_basemap(ax=ax, crs=study_crs, source=cx_tile_2)\n",
    "\n",
    "    plot_func.save_fig(fig, osm_results_static_maps_fp + \"tagsincompatible_osm\")\n",
    "\n",
    "else:\n",
    "    print(\"There are no incompatible tag combinations to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting incompatible tag geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "incompatible_tags_edge_ids = eval_func.check_incompatible_tags(\n",
    "    osm_edges, incompatible_tags_dict, store_edge_ids=True\n",
    ")\n",
    "\n",
    "if len(incompatible_tags_edge_ids) > 0:\n",
    "\n",
    "    incompatible_tags_fg = []\n",
    "\n",
    "    # iterate through dict of queries,\n",
    "    for i, key in enumerate(list(incompatible_tags_edge_ids.keys())):\n",
    "        # create one feature group for each query\n",
    "        # and append it to list\n",
    "        incompatible_tags_fg.append(\n",
    "            plot_func.make_edgefeaturegroup(\n",
    "                gdf=osm_edges[\n",
    "                    osm_edges[\"edge_id\"].isin(incompatible_tags_edge_ids[key])\n",
    "                ],\n",
    "                mycolor=pdict[\"basecols\"][i],\n",
    "                myweight=pdict[\"line_emp\"],\n",
    "                nametag=\"Incompatible tags: \" + key,\n",
    "                show_edges=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ### Make marker feature group\n",
    "    edge_ids = [\n",
    "        item\n",
    "        for sublist in list(incompatible_tags_edge_ids.values())\n",
    "        for item in sublist\n",
    "    ]  # get ids of all edges that have incompatible tags\n",
    "\n",
    "    mfg = plot_func.make_markerfeaturegroup(\n",
    "        osm_edges.loc[osm_edges[\"edge_id\"].isin(edge_ids)], nametag=\"Incompatible tag marker\", show_markers=True\n",
    "    )\n",
    "    incompatible_tags_fg.append(mfg)\n",
    "\n",
    "    # create interactive map\n",
    "    m = plot_func.make_foliumplot(\n",
    "        feature_groups=incompatible_tags_fg,\n",
    "        layers_dict=folium_layers,\n",
    "        center_gdf=osm_nodes,\n",
    "        center_crs=osm_nodes.crs,\n",
    "    )\n",
    "\n",
    "    bounds = plot_func.compute_folium_bounds(osm_nodes_simplified)\n",
    "    m.fit_bounds(bounds)\n",
    "\n",
    "    m.save(osm_results_inter_maps_fp + \"tagsincompatible_osm.html\")\n",
    "\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(incompatible_tags_edge_ids) > 0:\n",
    "    print(\"Interactive map saved at \" + osm_results_inter_maps_fp.lstrip(\"../\") + \"tagsincompatible_osm.html\")\n",
    "else:\n",
    "    print(\"There are no incompatible tag combinations to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging patterns\n",
    "\n",
    "Identifying bicycle infrastructure in OSM can be tricky due to the many different ways in which the presence of bicycle infrastructure can be indicated. The [OSM Wiki](https://wiki.openstreetmap.org/wiki/Main_Page) is a great resource for recommendations for how OSM features should be tagged, but some inconsistencies and local variations can remain. The analysis of tagging patterns allows to visually explore some of the potential inconsistencies.\n",
    "\n",
    "Regardless of how the bicycle infrastructure is defined, examining which tags contribute to which parts of the bicycle network allows to visually examine patterns in tagging methods. It also allows to estimate whether some elements of the query will lead to the inclusion of too many or too few features.\n",
    "\n",
    "Likewise, 'double tagging' where several different tags have been used to indicate bicycle infrastructure can lead to misclassifications of the data. For this reason, identifying features that are included in more than one of the queries defining bicycle infrastructure can indicate issues with the tagging quality.\n",
    "\n",
    "**Method**\n",
    "\n",
    "We first plot individual subsets of the OSM data set for each of the queries listed in `bicycle_infrastructure_queries`, as defined in the `config.yml` file. The subset defined by a query is the set of edges for which this query is *True*. Since several queries can be *True* for the same edge, the subsets can overlap. In the second step below, all overlaps between 2 or more queries are plotted, i.e. all edges that have been assigned several, potentially competing, tags.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "The plots for each tagging type allow for a quick visual overview of different tagging patterns present in the area. Based on local knowledge, the user may estimate whether the differences in tagging types are due to actual physical differences in the infrastructure or rather an artefact of the OSM data. Next, the user can access overlaps between different tags; depending on the specific tags, this may or may not be a data quality issue. For example, in case of `'cycleway:right'` and `'cycleway:left'`, having data for both tags is valid, but other combinations such as `'cycleway'='track'` and `'cycleway:left=lane'` gives an ambiguouos picture of what type of bicycle infrastructure is present.\n",
    "\n",
    "#### Tagging types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_edges[\"tagging_type\"] = \"\"\n",
    "\n",
    "for k, q in bicycle_infrastructure_queries.items():\n",
    "\n",
    "    try:\n",
    "        ox_filtered = osm_edges.query(q)\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Exception occured when quering with:\", q)\n",
    "\n",
    "    osm_edges.loc[ox_filtered.index, \"tagging_type\"] = (\n",
    "        osm_edges.loc[ox_filtered.index, \"tagging_type\"] + k\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "# Interactive plot of tagging types\n",
    "\n",
    "# initialize list of folium feature groups (one per tagging type)\n",
    "tagging_types_fg = []\n",
    "\n",
    "# iterate through dict of queries,\n",
    "i = 0  # index for color change\n",
    "for key in bicycle_infrastructure_queries.keys():\n",
    "    # create one feature group for each query\n",
    "    # and append it to list\n",
    "    tagging_types_fg.append(\n",
    "        plot_func.make_edgefeaturegroup(\n",
    "            gdf=osm_edges[osm_edges[\"tagging_type\"] == key],\n",
    "            mycolor=pdict[\"basecols\"][i],\n",
    "            myweight=2,\n",
    "            nametag=\"Tagging type \" + key,\n",
    "            show_edges=True,\n",
    "        )\n",
    "    )\n",
    "    i += 1  # update index\n",
    "\n",
    "# create interactive map\n",
    "m = plot_func.make_foliumplot(\n",
    "    feature_groups=tagging_types_fg,\n",
    "    layers_dict=folium_layers,\n",
    "    center_gdf=osm_nodes_simplified,\n",
    "    center_crs=osm_nodes_simplified.crs,\n",
    ")\n",
    "\n",
    "bounds = plot_func.compute_folium_bounds(osm_nodes_simplified)\n",
    "m.fit_bounds(bounds)\n",
    "\n",
    "m.save(osm_results_inter_maps_fp + \"taggingtypes_osm.html\")\n",
    "\n",
    "for k, v in bicycle_infrastructure_queries.items():\n",
    "    print(\"Tagging type \" + k + \": \" + v)\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interactive map saved at \" + osm_results_inter_maps_fp.lstrip(\"../\") + \"taggingtypes_osm.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot all osm_edges which are returned for more than one tagging_type\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "tagging_combinations = list(osm_edges.tagging_type.unique())\n",
    "tagging_combinations = [x for x in tagging_combinations if len(x) > 1]\n",
    "\n",
    "if len(tagging_combinations) > 0:\n",
    "\n",
    "    for i, t in enumerate(tagging_combinations):\n",
    "\n",
    "        fig, ax = plt.subplots(1, figsize=pdict[\"fsmap\"])\n",
    "\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if len(osm_edges.loc[osm_edges[\"tagging_type\"] == t]) < 10:\n",
    "\n",
    "            grid.plot(ax=ax, facecolor=\"none\", edgecolor=\"none\", alpha=0)\n",
    "            osm_edges.loc[osm_edges[\"tagging_type\"] == t][\"geometry\"].centroid.plot(\n",
    "                ax=ax, color=pdict[\"osm_emp\"], markersize=30\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            grid.plot(ax=ax, facecolor=\"none\", edgecolor=\"none\", alpha=0)\n",
    "            osm_edges.loc[osm_edges[\"tagging_type\"] == t][\"geometry\"].centroid.plot(\n",
    "                ax=ax, color=pdict[\"osm_emp\"], markersize=5\n",
    "            )\n",
    "\n",
    "\n",
    "        columns_in_query = \"\"\n",
    "        for value in t:\n",
    "            tag_name = bicycle_infrastructure_queries[value].split(\" \")[0]\n",
    "            columns_in_query = columns_in_query + tag_name + \" + \"\n",
    "\n",
    "        columns_in_query = columns_in_query[:-3]\n",
    "\n",
    "        title = area_name+\": OSM bicycle infrastructure defined with tags: \" + columns_in_query\n",
    "\n",
    "        ax.set_title(title)\n",
    "\n",
    "        cx.add_basemap(ax=ax, crs=study_crs, source=cx_tile_2)\n",
    "\n",
    "        filepath_extension = columns_in_query.replace(\" + \", \"-\")\n",
    "        \n",
    "        plot_func.save_fig(fig, osm_results_static_maps_fp + f\"tagscompeting_{filepath_extension}_osm\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "if len(tagging_combinations) > 0:\n",
    "\n",
    "    # set seed for colors\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # generate enough random colors to plot all tagging combinations\n",
    "    randcols = [colors.to_hex(rgbcol) for rgbcol in np.random.rand(len(tagging_combinations), 3)]\n",
    "\n",
    "    # initialize list of feature groups (one for each tagging combination)\n",
    "    tag_featuregroups = []\n",
    "    \n",
    "    for i, t in enumerate(tagging_combinations):\n",
    "\n",
    "        columns_in_query = \"\"\n",
    "\n",
    "        for value in t:\n",
    "            tag_name = bicycle_infrastructure_queries[value].split(\" \")[0]\n",
    "            columns_in_query = columns_in_query + tag_name + \" + \"\n",
    "\n",
    "        columns_in_query = columns_in_query[:-3]\n",
    "\n",
    "        tag_featuregroup = plot_func.make_edgefeaturegroup(\n",
    "            gdf=osm_edges.loc[osm_edges[\"tagging_type\"] == t],\n",
    "            mycolor=randcols[i],\n",
    "            myweight=pdict[\"line_emp\"],\n",
    "            nametag=columns_in_query,\n",
    "            show_edges=True,\n",
    "        )\n",
    "\n",
    "        tag_featuregroups.append(tag_featuregroup)\n",
    "\n",
    "        \n",
    "    m = plot_func.make_foliumplot(\n",
    "        feature_groups=tag_featuregroups,\n",
    "        layers_dict=folium_layers,\n",
    "        center_gdf=osm_nodes_simplified,\n",
    "        center_crs=osm_nodes_simplified.crs,\n",
    "    )\n",
    "\n",
    "    bounds = plot_func.compute_folium_bounds(osm_nodes_simplified)\n",
    "    m.fit_bounds(bounds)\n",
    "\n",
    "    m.save(osm_results_inter_maps_fp + \"taggingcombinations_osm.html\") \n",
    "\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tagging_combinations) > 0:\n",
    "    print(\"Interactive map saved at \" + osm_results_inter_maps_fp.lstrip(\"../\") + \"taggingcombinations_osm.html\")\n",
    "else:\n",
    "    print(\"There are no tagging combinations to plot.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network topology\n",
    "\n",
    "This section explores the geometric and topological features of the data. These are, for example, network density, disconnected components, and dangling (degree one) nodes. It also includes exploring whether there are nodes that are very close to each other but do not share an edge - a potential sign of edge undershoots - or if there are intersecting edges without a node at the intersection, which might indicate a digitizing error that will distort routing on the network.\n",
    "\n",
    "Due to the fragmented nature of most bicycle networks, many metrics, such as missing links or network gaps, can simply reflect the true extent of the infrastructure ([Natera Orozco et al., 2020](https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/gean.12324)). This is different for road networks, where e.g., disconnected components could more readily be interpreted as a data quality issue. Therefore, the analysis only takes very small network gaps into account as potential data quality issues.\n",
    "\n",
    "### Simplification outcome\n",
    "\n",
    "To compare the structure and true ratio between nodes and edges in the network, a simplified network representation which only includes nodes at endpoints and intersections was created in notebook `1a` by removing all interstitial nodes.\n",
    "\n",
    "Comparing the degree distribution for the networks before and after simplification is a quick sanity check for the simplification routine. Typically, the vast majority of nodes in the non-simplified network will be of degree two; in the simplified network, however, most nodes will have degrees other than two. Degree two nodes are retained in only two cases: if they represent a connection point between two different types of infrastructure; or if they are needed in order to avoid self-loops (edges whose start and end points are identical) or multiple edges between the same pair of nodes. \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src='../../images/network_simplification_illustration.png' width=300/>\n",
    "\n",
    "*Non-simplified network (left) and simplified network (right)*.\n",
    "\n",
    "</p>\n",
    "\n",
    "**Method**\n",
    "\n",
    "The degree distributions before and after simplification are plotted below. \n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Typically, the degree distribution will go from high (before simplification) to low (after simplification) counts of degree two nodes, while it will not change for all other degrees (1, or 3 and higher). Further, the total number of nodes will see a strong decline. If the simplified graph still maintains a relatively high number of degree two nodes, or if the number of nodes with other degrees changes after the simplification, this might point to issues either with the graph conversion or with the simplification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease in network elements after simplification\n",
    "\n",
    "edge_percent_diff = (len(osm_edges) - len(osm_edges_simplified)) / len(osm_edges) * 100\n",
    "node_percent_diff = (len(osm_nodes) - len(osm_nodes_simplified)) / len(osm_nodes) * 100\n",
    "\n",
    "simplification_results = {\n",
    "    \"edge_percent_diff\": edge_percent_diff,\n",
    "    \"node_percent_diff\": node_percent_diff,\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Simplifying the network decreased the number of edges by {edge_percent_diff:.1f}% and the number of nodes by {node_percent_diff:.1f}%.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree distribution\n",
    "\n",
    "set_renderer(renderer_plot)\n",
    "fig, ax = plt.subplots(1, 2, figsize=pdict[\"fsbar_short\"], sharey=True)\n",
    "\n",
    "degree_sequence_before = sorted((d for n, d in osm_graph.degree()), reverse=True)\n",
    "degree_sequence_after = sorted(\n",
    "    (d for n, d in osm_graph_simplified.degree()), reverse=True\n",
    ")\n",
    "\n",
    "# Plot degree distributions\n",
    "ax[0].bar(*np.unique(degree_sequence_before, return_counts=True), tick_label = np.unique(degree_sequence_before), color=pdict[\"osm_base\"])\n",
    "ax[0].set_title(\"Before simplification\")\n",
    "ax[0].set_xlabel(\"Degree\")\n",
    "ax[0].set_ylabel(\"Nodes\")\n",
    "\n",
    "ax[1].bar(*np.unique(degree_sequence_after, return_counts=True), tick_label = np.unique(degree_sequence_after), color=pdict[\"osm_base\"])\n",
    "ax[1].set_title(\"After simplification\")\n",
    "ax[1].set_xlabel(\"Degree\")\n",
    "\n",
    "plt.suptitle(f\"{area_name}: OSM degree distributions\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_plots_fp + \"degree_dist_osm\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dangling nodes\n",
    "\n",
    "Dangling nodes are nodes of degree one, i.e. they have only one single edge attached to them. Most networks will naturally contain a number of dangling nodes. Dangling nodes can occur at actual dead-ends (representing a cul-de-sac) or at the endpoints of certain features, e.g. when a bicycle path ends in the middle of a street. However, dangling nodes can also occur as a data quality issue in case of over/undershoots (see next section). The number of dangling nodes in a network does to some extent also depend on the digitization method, as shown in the illustration below. \n",
    "\n",
    "Therefore, the presence of dangling nodes is in itself not a sign of low data quality. However, a high number of dangling nodes in an area that is not known for containing many dead-ends can indicate digitization errors and problems with edge over/undershoots.\n",
    "\n",
    "<!-- <table><tr><td><img src='../../images/dangling_nodes_illustration.png' width=300 /></td><td><img src='../../images/no_dangling_nodes_illustration.png' width=295 /></td></tr></table>\n",
    "\n",
    "*Left: Dangling nodes occur where road features end. Right: However, when separate features are joined at the end, there will be no dangling nodes.* -->\n",
    "\n",
    "<p align=\"center\">\n",
    "\n",
    "<img src='../../images/dangling_nodes_illustration_new.png' width=350/>\n",
    "\n",
    "*Left: Dangling nodes occur where road features end. Right: However, when separate features are joined at the end, there will be no dangling nodes.*\n",
    "\n",
    "</p>\n",
    "\n",
    "**Method**\n",
    "\n",
    "Below, a list of all dangling nodes is obtained with the help of `get_dangling_nodes`. Then, the network with all its nodes is plotted. The dangling nodes are shown in color, all other nodes are shown in black.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "We recommend a visual analysis in order to interpret the spatial distribution of dangling nodes, with particular attention to areas of high dangling node density. It is important to understand where dangling nodes come from: are they actual dead-ends or digitization errors (e.g., over/undershoots)? A higher number of digitization errors points to lower data quality.\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "outputs": [],
   "source": [
    "# Compute number of dangling nodes\n",
    "dangling_nodes = eval_func.get_dangling_nodes(\n",
    "    osm_edges_simplified, osm_nodes_simplified\n",
    ")\n",
    "\n",
    "# Export results\n",
    "dangling_nodes.to_file(osm_results_data_fp + \"dangling_nodes.gpkg\", index=False)\n",
    "\n",
    "# Compute local count and pct of dangling nodes\n",
    "dn_osm_joined = gpd.overlay(\n",
    "    dangling_nodes, grid[[\"geometry\", \"grid_id\"]], how=\"intersection\"\n",
    ")\n",
    "df = eval_func.count_features_in_grid(dn_osm_joined, \"osm_dangling_nodes\")\n",
    "grid = eval_func.merge_results(grid, df, \"left\")\n",
    "\n",
    "grid[\"osm_dangling_nodes_pct\"] = np.round(\n",
    "    100 * grid.count_osm_dangling_nodes / grid.count_osm_simplified_nodes, 2\n",
    ")\n",
    "\n",
    "# set to zero where there are simplified nodes but no dangling nodes\n",
    "grid[\"osm_dangling_nodes_pct\"].loc[\n",
    "    grid.count_osm_simplified_nodes.notnull() & grid.osm_dangling_nodes_pct.isnull()\n",
    "] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dangling nodes\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "fig, ax = plt.subplots(1, figsize=pdict[\"fsmap\"])\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=\"1%\")\n",
    "\n",
    "grid.plot(\n",
    "    cax=cax,\n",
    "    column=\"osm_dangling_nodes_pct\",\n",
    "    ax=ax,\n",
    "    alpha=pdict[\"alpha_grid\"],\n",
    "    cmap=pdict[\"pos\"],\n",
    "    legend=True,\n",
    ")\n",
    "\n",
    "# add no data patches\n",
    "grid[grid[\"count_osm_simplified_nodes\"].isnull()].plot(\n",
    "    cax=cax,\n",
    "    ax=ax,\n",
    "    facecolor=pdict[\"nodata_face\"],\n",
    "    edgecolor=pdict[\"nodata_edge\"],\n",
    "    linewidth= pdict[\"line_nodata\"],\n",
    "    hatch=pdict[\"nodata_hatch\"],\n",
    "    alpha=pdict[\"alpha_nodata\"],\n",
    ")\n",
    "\n",
    "ax.legend(handles=[nodata_patch], loc=\"upper right\")\n",
    "ax.set_title(f\"{area_name}: OSM percent of dangling nodes\")\n",
    "ax.set_axis_off()\n",
    "cx.add_basemap(ax=ax, crs=study_crs, source=cx_tile_2)\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_static_maps_fp + \"pct_dangling_nodes_osm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "# Interactive plot of dangling nodes\n",
    "\n",
    "edges_simplified_folium = plot_func.make_edgefeaturegroup(\n",
    "    gdf=osm_edges_simplified,\n",
    "    mycolor=pdict[\"base\"],\n",
    "    myweight=pdict[\"line_base\"],\n",
    "    nametag=\"Edges\",\n",
    "    show_edges=True,\n",
    ")\n",
    "\n",
    "nodes_simplified_folium = plot_func.make_nodefeaturegroup(\n",
    "    gdf=osm_nodes_simplified,\n",
    "    mysize=pdict[\"mark_base\"],\n",
    "    mycolor=pdict[\"base\"],\n",
    "    nametag=\"All nodes\",\n",
    "    show_nodes=True,\n",
    ")\n",
    "\n",
    "dangling_nodes_folium = plot_func.make_nodefeaturegroup(\n",
    "    gdf=dangling_nodes,\n",
    "    mysize=pdict[\"mark_emp\"],\n",
    "    mycolor= pdict[\"osm_base\"],\n",
    "    nametag=\"Dangling nodes\",\n",
    "    show_nodes=True,\n",
    ")\n",
    "\n",
    "m = plot_func.make_foliumplot(\n",
    "    feature_groups=[\n",
    "        edges_simplified_folium,\n",
    "        nodes_simplified_folium,\n",
    "        dangling_nodes_folium,\n",
    "    ],\n",
    "    layers_dict=folium_layers,\n",
    "    center_gdf=osm_nodes_simplified,\n",
    "    center_crs=osm_nodes_simplified.crs,\n",
    ")\n",
    "\n",
    "bounds = plot_func.compute_folium_bounds(osm_nodes_simplified)\n",
    "m.fit_bounds(bounds)\n",
    "\n",
    "m.save(osm_results_inter_maps_fp + \"danglingmap_osm.html\")\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interactive map saved at \" + osm_results_inter_maps_fp.lstrip(\"../\") + \"danglingmap_osm.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under/overshoots \n",
    "\n",
    "When two nodes in a simplified network are placed within a distance of a few meters, but do not share a common edge, it is often due to an edge over/undershoot or another digitizing error. An undershoot occurs when two features are supposed to meet, but instead are just in close proximity to each other. An overshoot occurs when two features meet and one of them extends beyond the other. See the image below for an illustration. For a more detailed explanation of over/undershoots, see the [GIS Lounge website](https://www.gislounge.com/digitizing-errors-in-gis/).\n",
    "\n",
    "<p align=\"center\">\n",
    "\n",
    "<img src='../../images/over_undershoots2.png' width=350/>\n",
    "\n",
    "*Left: Undershoots happen when two line features are not properly joined, for example at an intersection. Right: Overshoots refer to situations where a line feature extends too far beyond at intersecting line, rather than ending at the intersection.* \n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "**Method**\n",
    "\n",
    "*Undershoots:* First, the `length_tolerance` (in meters) is defined in the cell below. Then, with `find_undershoots`, all pairs of dangling nodes that have a maximum of `length_tolerance` distance between them, are identified as undershoots, and the results are plotted.\n",
    "\n",
    "*Overshoots:* First, the `length_tolerance` (in meters) is defined in the cell below. Then, with `find_overshoots`, all network edges that have a dangling node attached to them and that have a maximum length of `length_tolerance` are identifed as overshoots, and the results are plotted.\n",
    "\n",
    "The method for over/undershoot detection is inspired by [Neis et al. (2012)](https://www.mdpi.com/1999-5903/4/1/1).\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Under/overshoots are not necessarily always a data quality issue - they might be instead an accurate representation of the network conditions or of the digitization strategy. For example, a cycle path might end abruptly soon after a turn, which results in an overshoot. Protected cycle paths are sometimes digitized in OSM as interrupted at intersections which results in intersection undershoots.\n",
    "\n",
    "The interpretation of the impact of over/undershoots on data quality is context dependent. For certain applications, such as routing, overshoots do not present a particular challenge; they can, however, pose an issue for other applications such as network analysis, given that they skew the network structure.  Undershoots, on the contrary, are a serious problem for routing applications, especially if only bicycle infrastructure is considered. They also pose a problem for network analysis, for example for any path-based metric, such as most centrality measures like betweenness centrality.\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>User configurations</b>\n",
    "<br>\n",
    "<br>\n",
    "In the analysis of over and undershoots, the user can modify the length tolerance for both over and undershoots. <br>\n",
    "For example, a length tolerance of 3 meters for overshoots means that only edge snippets with a length of 3 meters or less are considered overshoots.<br>\n",
    "A tolerance of 5 meters for undershoots means that only gaps of 5 meters or less are considered undershoots.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "outputs": [],
   "source": [
    "# USER INPUT: LENGTH TOLERANCE FOR OVER- AND UNDERSHOOTS\n",
    "length_tolerance_over = 3\n",
    "length_tolerance_under = 3\n",
    "\n",
    "for s in [length_tolerance_over, length_tolerance_under]:\n",
    "    assert isinstance(s, int) or isinstance(s, float), print(\n",
    "        \"Settings must be integer or float values!\"\n",
    "    )\n",
    "\n",
    "print(f\"Running overshoot analysis with a tolerance threshold of {length_tolerance_over} m.\")\n",
    "print(f\"Running undershoot analysis with a tolerance threshold of {length_tolerance_under} m.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overshoots\n",
    "\n",
    "overshoots = eval_func.find_overshoots(\n",
    "    dangling_nodes,\n",
    "    osm_edges_simplified,\n",
    "    length_tolerance_over,\n",
    "    return_overshoot_edges=True,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{len(overshoots)} potential overshoots were identified using a length tolerance of {length_tolerance_over} m.\"\n",
    ")\n",
    "\n",
    "### Undershoots\n",
    "undershoot_dict, undershoot_nodes = eval_func.find_undershoots(\n",
    "    dangling_nodes,\n",
    "    osm_edges_simplified,\n",
    "    length_tolerance_under,\n",
    "    \"edge_id\",\n",
    "    return_undershoot_nodes=True,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{len(undershoot_nodes)} potential undershoots were identified using a length tolerance of {length_tolerance_under} m.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "\n",
    "overshoots[[\"edge_id\", \"length\"]].to_csv(\n",
    "    osm_results_data_fp + f\"overshoot_edges_{length_tolerance_over}.csv\", header = [\"edge_id\", \"length (m)\"], index = False\n",
    ")\n",
    "\n",
    "pd.DataFrame(undershoot_nodes[\"osmid\"].to_list(), columns=[\"node_id\"]).to_csv(\n",
    "    osm_results_data_fp + f\"undershoot_nodes_{length_tolerance_under}.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "# Interactive plot of under/overshoots\n",
    "\n",
    "simplified_edges_folium = plot_func.make_edgefeaturegroup(\n",
    "    gdf=osm_edges_simplified,\n",
    "    mycolor=pdict[\"base\"],\n",
    "    myweight=pdict[\"line_base\"],\n",
    "    nametag=\"Edges\",\n",
    "    show_edges=True,\n",
    ")\n",
    "\n",
    "fg = [simplified_edges_folium]\n",
    "\n",
    "if len(overshoots) > 0 or len(undershoot_nodes) > 0:\n",
    "\n",
    "    if len(overshoots) > 0:\n",
    "\n",
    "        overshoots_folium = plot_func.make_edgefeaturegroup(\n",
    "            gdf=overshoots,\n",
    "            mycolor=pdict[\"osm_contrast\"],\n",
    "            myweight=pdict[\"line_emp2\"],\n",
    "            nametag=\"Overshoots\",\n",
    "            show_edges=True,\n",
    "        )\n",
    "\n",
    "        fg.append(overshoots_folium)\n",
    "\n",
    "    if len(undershoot_nodes) > 0:\n",
    "\n",
    "        undershoot_nodes_folium = plot_func.make_nodefeaturegroup(\n",
    "            gdf=undershoot_nodes,\n",
    "            mysize=pdict[\"mark_emp\"],\n",
    "            mycolor=pdict[\"osm_contrast2\"],\n",
    "            nametag=\"Undershoot nodes\",\n",
    "            show_nodes=True,\n",
    "        )\n",
    "\n",
    "        fg.append(undershoot_nodes_folium)\n",
    "\n",
    "    m = plot_func.make_foliumplot(\n",
    "        feature_groups=fg,\n",
    "        layers_dict=folium_layers,\n",
    "        center_gdf=osm_nodes_simplified,\n",
    "        center_crs=osm_nodes_simplified.crs,\n",
    "    )\n",
    "\n",
    "    bounds = plot_func.compute_folium_bounds(osm_nodes_simplified)\n",
    "    m.fit_bounds(bounds)\n",
    "\n",
    "    m.save(\n",
    "        osm_results_inter_maps_fp\n",
    "        + f\"underovershoots_{length_tolerance_under}_{length_tolerance_over}_osm.html\"\n",
    "    )\n",
    "\n",
    "    display(m)\n",
    "\n",
    "if len(undershoot_nodes) == 0:\n",
    "    print(\"There are no undershoots to plot.\")\n",
    "if len(overshoots) == 0:\n",
    "    print(\"There are no overshoots to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(overshoots) > 0 or len(undershoot_nodes) > 0:\n",
    "    print(\"Interactive map saved at \" + osm_results_inter_maps_fp.lstrip(\"../\") + f\"underovershoots_{length_tolerance_under}_{length_tolerance_over}_osm.html\")\n",
    "else:\n",
    "    print(\"There are no under/overshoots to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing intersection nodes\n",
    "\n",
    "When two edges intersect without having a node at the intersection - and if neither edges are tagged as a bridge or a tunnel - there is a clear indication of a topology error. \n",
    "\n",
    "**Method**\n",
    "\n",
    "First, with the help of `check_intersection`, each edge which is not tagged as either tunnel or bridge is checked for any *crossing* with another edge of the network. If this is the case, the edge is marked as having an intersection issue. The number of intersection issues found is printed and the results are plotted for visual analysis. The method is inspired by [Neis et al. (2012)](https://www.mdpi.com/1999-5903/4/1/1).\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "A higher number of intersection issues points to a lower data quality. However, it is recommended with a manual visual check of all intersection issues with a certain knowledge of the area, in order to determine the origin of intersection issues and confirm/correct/reject them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning</b>\n",
    "<p>\n",
    "This is the most computationally intensive operation in this notebook. It can take several times longer than all other sections.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_nodes_edge_ids, edges_with_missing_nodes = eval_func.find_missing_intersections(\n",
    "    osm_edges, \"edge_id\"\n",
    ")\n",
    "\n",
    "count_intersection_issues = (\n",
    "    len(missing_nodes_edge_ids) / 2\n",
    ")  # The number of issues is counted twice since both intersecting osm_edges are returned\n",
    "\n",
    "print(\n",
    "    f\"{count_intersection_issues:.0f} place(s) appear to be missing an intersection node or a bridge/tunnel tag.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "\n",
    "if count_intersection_issues > 0: \n",
    "    pd.DataFrame(data=missing_nodes_edge_ids, columns=[\"edge_id\"]).to_csv(\n",
    "        osm_results_data_fp + \"edges_missing_intersections.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "# Interactive plot of intersection issues\n",
    "\n",
    "if count_intersection_issues > 0:\n",
    "\n",
    "    simplified_edges_folium = plot_func.make_edgefeaturegroup(\n",
    "        gdf=osm_edges_simplified,\n",
    "        mycolor=pdict[\"base\"],\n",
    "        myweight=pdict[\"line_base\"],\n",
    "        nametag=\"All edges\",\n",
    "        show_edges=True,\n",
    "    )\n",
    "\n",
    "    intersection_issues_folium = plot_func.make_edgefeaturegroup(\n",
    "        gdf=edges_with_missing_nodes,\n",
    "        mycolor=pdict[\"osm_contrast\"],\n",
    "        myweight=pdict[\"line_emp\"],\n",
    "        nametag=\"Intersection issues: edges\",\n",
    "        show_edges=True,\n",
    "    )\n",
    "\n",
    "    mfg = plot_func.make_markerfeaturegroup(\n",
    "        edges_with_missing_nodes, \n",
    "        nametag=\"Intersection issues: marker at missing node\", \n",
    "        show_markers=True\n",
    "    )\n",
    "  \n",
    "    m = plot_func.make_foliumplot(\n",
    "        feature_groups=[simplified_edges_folium, intersection_issues_folium, mfg],\n",
    "        layers_dict=folium_layers,\n",
    "        center_gdf=osm_nodes_simplified,\n",
    "        center_crs=osm_nodes_simplified.crs,\n",
    "    )\n",
    "\n",
    "    bounds = plot_func.compute_folium_bounds(osm_nodes_simplified)\n",
    "    m.fit_bounds(bounds)\n",
    "\n",
    "    m.save(osm_results_inter_maps_fp + \"intersection_issues_osm.html\")\n",
    "\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if count_intersection_issues > 0:\n",
    "    print(\"Interactive map saved at \" + osm_results_inter_maps_fp.lstrip(\"../\") + \"intersection_issues_osm.html\")\n",
    "else:\n",
    "    print(\"There are no intersection problems to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network components\n",
    "\n",
    "Disconnected components do not share any elements (nodes/edges). In other words, there is no network path that could lead from one disconnected component to the other. As mentioned above, most real-world networks of bicycle infrastructure do consist of many disconnected components ([Natera Orozco et al., 2020](https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/gean.12324)). However, when two disconnected components are very close to each other, it might be a sign of a missing edge or another digitizing error.\n",
    "\n",
    "**Method**\n",
    "\n",
    "First, with the help of `return_components`, a list of all (disconnected) components of the network is obtained. The total number of components is printed and all components are plotted in different colors for visual analysis. Next, the component size distribution (with components ordered by the network length they contain) is plotted, followed by a plot of the largest connected component. \n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "As with many of the previous analysis steps, knowledge of the area is crucial for a correct interpretation of component analysis. Given that the data represents the actual infrastructure accurately, bigger components indicate coherent network parts, while smaller components indicate scattered infrastructure (e.g., one single bicycle path along a street that does not connect to any other bicycle infrastructure). A high number of disconnected components in near vicinity of each other indicates digitization errors or missing data.\n",
    "\n",
    "### Disconnected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_components = eval_func.return_components(osm_graph_simplified)\n",
    "print(\n",
    "    f\"The network in the study area has {len(osm_components)} disconnected components.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot disconnected components\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "\n",
    "# set seed for colors\n",
    "np.random.seed(42)\n",
    "\n",
    "# generate enough random colors to plot all components\n",
    "randcols = np.random.rand(len(osm_components), 3)\n",
    "randcols[0, :] = col_to_rgb(pdict['osm_base'])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=pdict[\"fsmap\"])\n",
    "\n",
    "ax.set_title(f\"{area_name}: OSM disconnected components\")\n",
    "\n",
    "ax.set_axis_off()\n",
    "\n",
    "for j, c in enumerate(osm_components):\n",
    "    if len(c.edges) > 0:\n",
    "        edges = ox.graph_to_gdfs(c, nodes=False)\n",
    "        edges.plot(ax=ax, color=randcols[j])\n",
    "\n",
    "cx.add_basemap(ax=ax, crs=study_crs, source=cx_tile_2)\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_static_maps_fp + \"all_components_osm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components per grid cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign component ids to grid\n",
    "\n",
    "grid = eval_func.assign_component_id_to_grid(\n",
    "    osm_edges_simplified,\n",
    "    osm_edges_simp_joined,\n",
    "    osm_components,\n",
    "    grid,\n",
    "    prefix=\"osm\",\n",
    "    edge_id_col=\"edge_id\",\n",
    ")\n",
    "\n",
    "fill_na_dict = {\"component_ids_osm\": \"\"}\n",
    "grid.fillna(value=fill_na_dict, inplace=True)\n",
    "\n",
    "grid[\"component_count_osm\"] = grid.component_ids_osm.apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of components per grid cell\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=pdict[\"fsmap\"])\n",
    "\n",
    "ncolors = grid[\"component_count_osm\"].max()\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=\"1%\")\n",
    "\n",
    "mycm = cm.get_cmap(pdict[\"seq\"], ncolors) \n",
    "grid[grid.component_count_osm>0].plot(\n",
    "    cax=cax,\n",
    "    ax=ax,\n",
    "    column=\"component_count_osm\",\n",
    "    legend=True,\n",
    "    legend_kwds={'ticks': list(range(1, ncolors+1))},\n",
    "    cmap=mycm,\n",
    "    alpha=pdict[\"alpha_grid\"],\n",
    ")\n",
    "\n",
    "# add no data patches\n",
    "grid[grid[\"count_osm_edges\"].isnull()].plot(\n",
    "    cax=cax,\n",
    "    ax=ax,\n",
    "    facecolor=pdict[\"nodata_face\"],\n",
    "    edgecolor=pdict[\"nodata_edge\"],\n",
    "    linewidth= pdict[\"line_nodata\"],\n",
    "    hatch=pdict[\"nodata_hatch\"],\n",
    "    alpha=pdict[\"alpha_nodata\"],\n",
    ")\n",
    "\n",
    "ax.legend(handles=[nodata_patch], loc=\"upper right\")\n",
    "\n",
    "cx.add_basemap(ax=ax, crs=study_crs, source=cx_tile_2)\n",
    "ax.set_title(area_name + \": OSM number of components in grid cells\")\n",
    "ax.set_axis_off()\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_static_maps_fp + f\"number_of_components_in_grid_cells_osm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component length distribution\n",
    "\n",
    "The distribution of all network component lengths can be visualized in a so-called *Zipf plot*, which orders the lengths of each component by rank, showing the largest component's length on the left, then the second largest component's length, etc., until the smallest component's length on the right. When a Zipf plot follows a straight line in [log-log scale](https://en.wikipedia.org/wiki/Logarithmic_scale), it means that there is a much higher chance to find small disconnected components than expected from traditional distributions [(Clauset et al., 2009)]( https://epubs.siam.org/doi/abs/10.1137/070710111). This can mean that there has been no consolidation of the network, only piece-wise or random additions [(Szell et al., 2022)](https://www.nature.com/articles/s41598-022-10783-y), or that the data itself suffers from many gaps and topology errors resulting in small disconnected components.\n",
    "\n",
    "However, it can also happen that the largest connected component (the leftmost marker in the plot at rank $10^0$) is a clear outlier, while the rest of the plot follows a different shape. This can mean that at the infrastructure level, most of the infrastructure has been connected to one large component, and that the data reflects this - i.e. the data is not suffering from gaps and missing links to a large extent.\n",
    "\n",
    "Bicycle networks might also be somewhere inbetween, with several large components as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zipf plot of component lengths\n",
    "\n",
    "set_renderer(renderer_plot)\n",
    "\n",
    "components_length = {}\n",
    "for i, c in enumerate(osm_components):\n",
    "    c_length = 0\n",
    "    for (u, v, l) in c.edges(data=\"length\"):\n",
    "        c_length += l\n",
    "    components_length[i] = c_length\n",
    "\n",
    "components_df = pd.DataFrame.from_dict(components_length, orient=\"index\")\n",
    "components_df.rename(columns={0: \"component_length\"}, inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=pdict[\"fsbar_small\"])\n",
    "axes = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "axes.set_axisbelow(True)\n",
    "axes.grid(True,which=\"major\",ls=\"dotted\")\n",
    "yvals = sorted(list(components_df[\"component_length\"] / 1000), reverse = True)\n",
    "axes.scatter(\n",
    "    x=[i+1 for i in range(len(components_df))],\n",
    "    y=yvals,\n",
    "    s=18,\n",
    "    color=pdict[\"osm_base\"],\n",
    ")\n",
    "axes.set_ylim(ymin=10**math.floor(math.log10(min(yvals))), ymax=10**math.ceil(math.log10(max(yvals))))\n",
    "axes.set_xscale(\"log\")\n",
    "axes.set_yscale(\"log\")\n",
    "\n",
    "axes.set_ylabel(\"Component length [km]\")\n",
    "axes.set_xlabel(\"Component rank (largest to smallest)\")\n",
    "axes.set_title(area_name+\": OSM component length distribution\")\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_plots_fp + \"component_length_distribution_osm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_cc = max(osm_components, key=len)\n",
    "\n",
    "largest_cc_length = 0\n",
    "\n",
    "for (u, v, l) in largest_cc.edges(data=\"length\"):\n",
    "\n",
    "    largest_cc_length += l\n",
    "\n",
    "largest_cc_pct = largest_cc_length / components_df[\"component_length\"].sum() * 100\n",
    "\n",
    "print(\n",
    "    f\"The largest connected component contains {largest_cc_pct:.2f}% of the network length.\"\n",
    ")\n",
    "\n",
    "# Get edges in largest cc\n",
    "lcc_edges = ox.graph_to_gdfs(\n",
    "    G=largest_cc, nodes=False, edges=True, node_geometry=False, fill_edge_geometry=False\n",
    ")\n",
    "\n",
    "# Export to GPKG\n",
    "lcc_edges[[\"edge_id\", \"geometry\"]].to_file(\n",
    "    osm_results_data_fp + \"largest_connected_component.gpkg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of largest connected component\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "fig, ax = plt.subplots(1, 1, figsize=pdict[\"fsmap\"])\n",
    "osm_edges_simplified.plot(ax=ax, color = pdict[\"base\"], linewidth = 1.5, label = \"All smaller components\")\n",
    "lcc_edges.plot(ax=ax, color=pdict[\"osm_base\"], linewidth = 2, label = \"Largest connected component\")\n",
    "grid.plot(ax=ax,alpha=0)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(area_name + \": OSM largest connected component\")\n",
    "ax.legend()\n",
    "\n",
    "cx.add_basemap(ax=ax, crs=study_crs, source=cx_tile_2)\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_static_maps_fp + f\"largest_conn_comp_osm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "outputs": [],
   "source": [
    "# Save plot without basemap for potential report titlepage\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "fig, ax = plt.subplots(1, 1, figsize=pdict[\"fsmap\"])\n",
    "osm_edges_simplified.plot(ax=ax, color = pdict[\"base\"], linewidth = 1.5, label = \"Disconnected components\")\n",
    "lcc_edges.plot(ax=ax, color=pdict[\"osm_base\"], linewidth = 2, label = \"Largest connected component\")\n",
    "ax.set_axis_off()\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_static_maps_fp + f\"titleimage\",plot_res=\"high\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing links\n",
    "\n",
    "In the plot of potential missing links between components, all edges that are within the specified distance of an edge on another component are plotted. The gaps between disconnected edges are highlighted with a marker. The map thus highlights edges which, despite being in close proximity of each other, are disconnected and where it thus would not be possible to bike on cycling infrastructure between the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>User configuration</b>\n",
    "<p>\n",
    "In the analysis of potential missing links between components, the user must define the threshold for when the distance between two components is considered to be low enough that a digitization error is suspected.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MAX BUFFER DISTANCE BETWEEN COMPONENTS CONSIDERED A GAP/MISSING LINK\n",
    "component_min_distance = 10\n",
    "\n",
    "assert isinstance(component_min_distance, int) or isinstance(\n",
    "    component_min_distance, float\n",
    "), print(\"Setting must be integer or float value!\")\n",
    "\n",
    "print(f\"Running analysis with component distance threshold of {component_min_distance} meters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_gaps = eval_func.find_adjacent_components(\n",
    "    components=osm_components,\n",
    "    buffer_dist=component_min_distance,\n",
    "    crs=study_crs,\n",
    "    edge_id=\"edge_id\",\n",
    ")\n",
    "component_gaps_gdf = gpd.GeoDataFrame.from_dict(\n",
    "    component_gaps, orient=\"index\", geometry=\"geometry\", crs=study_crs\n",
    ")\n",
    "\n",
    "edge_ids = set(\n",
    "    component_gaps_gdf[\"edge_id\" + \"_left\"].to_list()\n",
    "    + component_gaps_gdf[\"edge_id\" + \"_right\"].to_list()\n",
    ")\n",
    "\n",
    "edge_ids = [int(i) for i in edge_ids]\n",
    "edges_with_gaps = osm_edges_simplified.loc[osm_edges_simplified.edge_id.isin(edge_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "pd.DataFrame(edge_ids, columns=[\"edge_id\"]).to_csv(\n",
    "    osm_results_data_fp + f\"component_gaps_edges_{component_min_distance}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "# Export gaps to GPKG\n",
    "component_gaps_gdf.to_file(\n",
    "    osm_results_data_fp + f\"component_gaps_centroids_{component_min_distance}.gpkg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "# Interactive plot of adjacent, potentially disconnected components\n",
    "\n",
    "if len(component_gaps) > 0:\n",
    "\n",
    "    simplified_edges_folium = plot_func.make_edgefeaturegroup(\n",
    "        gdf=osm_edges_simplified,\n",
    "        mycolor=pdict[\"osm_base\"],\n",
    "        myweight=pdict[\"line_base\"],\n",
    "        nametag=\"All edges\",\n",
    "        show_edges=True,\n",
    "    )\n",
    "\n",
    "    component_issues_edges_folium = plot_func.make_edgefeaturegroup(\n",
    "        gdf=edges_with_gaps,\n",
    "        mycolor=pdict[\"osm_emp\"],\n",
    "        myweight=pdict[\"line_emp\"],\n",
    "        nametag=\"Adjacent disconnected edges\",\n",
    "        show_edges=True,\n",
    "    )\n",
    "\n",
    "    component_issues_gaps_folium = plot_func.make_markerfeaturegroup(\n",
    "        gdf=component_gaps_gdf, nametag=\"Component gaps\", show_markers=True\n",
    "    )\n",
    "\n",
    "    m = plot_func.make_foliumplot(\n",
    "        feature_groups=[\n",
    "            simplified_edges_folium,\n",
    "            component_issues_edges_folium,\n",
    "            component_issues_gaps_folium,\n",
    "        ],\n",
    "        layers_dict=folium_layers,\n",
    "        center_gdf=osm_nodes_simplified,\n",
    "        center_crs=osm_nodes_simplified.crs,\n",
    "    )\n",
    "\n",
    "    bounds = plot_func.compute_folium_bounds(osm_nodes_simplified)\n",
    "    m.fit_bounds(bounds)\n",
    "\n",
    "    m.save(osm_results_inter_maps_fp + f\"component_gaps_{component_min_distance}_osm.html\")\n",
    "\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(component_gaps) > 0:\n",
    "    print(\"Interactive map saved at \" + osm_results_inter_maps_fp.lstrip(\"../\") + f\"component_gaps_{component_min_distance}_osm.html\")\n",
    "else:\n",
    "    print(\"There are no component gaps to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component connectivity\n",
    "\n",
    "Here we visualize differences between how many cells can be reached from each cell. This is a crude measure for network connectivity but has the benefit of being computationally cheap and thus able to quickly highlight stark differences in network connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_components_cell_count = eval_func.count_component_cell_reach(\n",
    "    components_df, grid, \"component_ids_osm\"\n",
    ")\n",
    "grid[\"cells_reached_osm\"] = grid[\"component_ids_osm\"].apply(\n",
    "    lambda x: eval_func.count_cells_reached(x, osm_components_cell_count)\n",
    "    if x != \"\"\n",
    "    else 0\n",
    ")\n",
    "\n",
    "grid[\"cells_reached_osm_pct\"] = grid.apply(\n",
    "    lambda x: np.round((x.cells_reached_osm / len(grid)) * 100, 2), axis=1\n",
    ")\n",
    "\n",
    "grid.loc[grid[\"cells_reached_osm_pct\"] == 0, \"cells_reached_osm_pct\"] = np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percent of cells reachable\n",
    "\n",
    "set_renderer(renderer_map)\n",
    "fig, ax = plt.subplots(1, 1, figsize=pdict[\"fsmap\"])\n",
    "\n",
    "# norm for color bars\n",
    "cbnorm_reach = colors.Normalize(vmin=0, vmax=100)\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=\"1%\")\n",
    "\n",
    "grid[grid.cells_reached_osm_pct > 0].plot(\n",
    "    cax=cax,\n",
    "    ax=ax,\n",
    "    column=\"cells_reached_osm_pct\",\n",
    "    legend=True,\n",
    "    cmap=pdict[\"seq\"],\n",
    "    norm=cbnorm_reach,\n",
    "    alpha=pdict[\"alpha_grid\"],\n",
    ")\n",
    "\n",
    "osm_edges_simplified.plot(ax=ax, color=pdict[\"osm_emp\"], linewidth=1)\n",
    "\n",
    "# add no data patches\n",
    "grid[grid[\"count_osm_edges\"].isnull()].plot(\n",
    "    cax=cax,\n",
    "    ax=ax,\n",
    "    facecolor=pdict[\"nodata_face\"],\n",
    "    edgecolor=pdict[\"nodata_edge\"],\n",
    "    linewidth= pdict[\"line_nodata\"],\n",
    "    hatch=pdict[\"nodata_hatch\"],\n",
    "    alpha=pdict[\"alpha_nodata\"],\n",
    ")\n",
    "\n",
    "ax.legend(handles=[nodata_patch], loc=\"upper right\")\n",
    "\n",
    "cx.add_basemap(ax=ax, crs=study_crs, source=cx_tile_2)\n",
    "ax.set_title(area_name+\": OSM percent of cells reachable\")\n",
    "ax.set_axis_off()\n",
    "\n",
    "plot_func.save_fig(fig, osm_results_static_maps_fp + \"percent_cells_reachable_grid_osm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_results = {}\n",
    "components_results[\"component_count\"] = len(osm_components)\n",
    "components_results[\"largest_cc_pct_size\"] = largest_cc_pct\n",
    "components_results[\"largest_cc_length\"] = largest_cc_length\n",
    "components_results[\"count_component_gaps\"] = len(component_gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out table summary of results\n",
    "\n",
    "summarize_results = {**density_results, **components_results}\n",
    "\n",
    "summarize_results[\"count_dangling_nodes\"] = len(dangling_nodes)\n",
    "summarize_results[\"count_intersection_issues\"] = count_intersection_issues\n",
    "summarize_results[\"count_overshoots\"] = len(overshoots)\n",
    "summarize_results[\"count_undershoots\"] = len(undershoot_nodes)\n",
    "summarize_results[\"count_incompatible_tags\"] = sum(\n",
    "    len(lst) for lst in incompatible_tags_results.values()\n",
    ")\n",
    "\n",
    "# Add total node count and total infrastructure length\n",
    "summarize_results[\"total_nodes\"] = len(osm_nodes_simplified)\n",
    "summarize_results[\"total_length\"] = osm_edges_simplified.infrastructure_length.sum() / 1000\n",
    "\n",
    "summarize_results_df = pd.DataFrame.from_dict(summarize_results, orient=\"index\")\n",
    "\n",
    "summarize_results_df.rename({0: \" \"}, axis=1, inplace=True)\n",
    "\n",
    "# Convert length to km\n",
    "summarize_results_df.loc[\"largest_cc_length\"] = (\n",
    "    summarize_results_df.loc[\"largest_cc_length\"] / 1000\n",
    ")\n",
    "\n",
    "summarize_results_df = summarize_results_df.reindex([\n",
    "    'total_length',\n",
    "    'protected_density_m_sqkm',\n",
    "    'unprotected_density_m_sqkm',\n",
    "    'mixed_density_m_sqkm',\n",
    "    'edge_density_m_sqkm',\n",
    "    'total_nodes',\n",
    "    'count_dangling_nodes',\n",
    "    'node_density_count_sqkm',\n",
    "    'dangling_node_density_count_sqkm',\n",
    "    'count_incompatible_tags',\n",
    "    'count_overshoots',\n",
    "    'count_undershoots',\n",
    "    'count_intersection_issues',\n",
    "    'component_count',\n",
    "    'largest_cc_length',\n",
    "    'largest_cc_pct_size', \n",
    "    'count_component_gaps'\n",
    "     ])\n",
    "\n",
    "rename_metrics = {\n",
    "    \"total_length\": \"Total infrastructure length (km)\",\n",
    "    \"total_nodes\": \"Nodes\",\n",
    "    \"edge_density_m_sqkm\": \"Bicycle infrastructure density (m/km2)\",\n",
    "    \"node_density_count_sqkm\": \"Nodes per km2\",\n",
    "    \"dangling_node_density_count_sqkm\": \"Dangling nodes per km2\",\n",
    "    \"protected_density_m_sqkm\": \"Protected bicycle infrastructure density (m/km2)\",\n",
    "    \"unprotected_density_m_sqkm\": \"Unprotected bicycle infrastructure density (m/km2)\",\n",
    "    \"mixed_density_m_sqkm\": \"Mixed protection bicycle infrastructure density (m/km2)\",\n",
    "    \"component_count\": \"Components\",\n",
    "    \"largest_cc_pct_size\": \"Largest component's share of network length\",\n",
    "    \"largest_cc_length\": \"Length of largest component (km)\",\n",
    "    \"count_component_gaps\": \"Component gaps\",\n",
    "    \"count_dangling_nodes\": \"Dangling nodes\",\n",
    "    \"count_intersection_issues\": \"Missing intersection nodes\",\n",
    "    \"count_overshoots\": \"Overshoots\",\n",
    "    \"count_undershoots\": \"Undershoots\",\n",
    "    \"count_incompatible_tags\": \"Incompatible tag combinations\",\n",
    "}\n",
    "\n",
    "summarize_results_df.rename(rename_metrics, inplace=True)\n",
    "summarize_results_df.style.pipe(format_osm_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "all_results[\"existing_tags\"] = existing_tags_results\n",
    "all_results[\"incompatible_tags_results\"] = incompatible_tags_results\n",
    "all_results[\"incompatible_tags_count\"] = sum(\n",
    "    len(lst) for lst in incompatible_tags_results.values()\n",
    ")\n",
    "all_results[\"network_density\"] = density_results\n",
    "all_results[\"count_intersection_issues\"] = count_intersection_issues\n",
    "all_results[\"count_overshoots\"] = len(overshoots)\n",
    "all_results[\"count_undershoots\"] = len(undershoot_nodes)\n",
    "all_results[\"dangling_node_count\"] = len(dangling_nodes)\n",
    "all_results[\"simplification_outcome\"] = simplification_results\n",
    "all_results[\"component_analysis\"] = components_results\n",
    "\n",
    "with open(osm_intrinsic_fp, \"w\") as outfile:\n",
    "    json.dump(all_results, outfile)\n",
    "\n",
    "\n",
    "# Save summary dataframe\n",
    "summarize_results_df.to_csv(\n",
    "    osm_results_data_fp + \"intrinsic_summary_results.csv\", index=True\n",
    ")\n",
    "\n",
    "# Save grid with results\n",
    "with open(osm_intrinsic_grid_fp, \"wb\") as f:\n",
    "    pickle.dump(grid, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "noex"
    ]
   },
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "print(\"Time of analysis: \" + strftime(\"%a, %d %b %Y %H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "bikedna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:51) [Clang 14.0.4 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "25d89d047ff73a4f08e1f58df0505313a978ba3f16552d4fb4e98a48d36b765b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
